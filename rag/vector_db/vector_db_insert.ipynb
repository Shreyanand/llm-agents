{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pymilvus sentence_transformers langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Milvus deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing connection to Milvus:\n",
      "Connection to Milvus successful, example collection exists.\n",
      "Collection already exists.\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import connections, utility\n",
    "\n",
    "MILVUS_HOST = \"<HOST>\"  # or replace with external route URL if accessible\n",
    "MILVUS_PORT = \"19530\"  # Default port for Milvus gRPC\n",
    "\n",
    "def test_milvus_connection():\n",
    "    # Connect to Milvus server\n",
    "    connections.connect(\"default\", host=MILVUS_HOST, port=MILVUS_PORT)\n",
    "    \n",
    "    # Test connection by checking the server version\n",
    "    try:\n",
    "        if utility.has_collection(\"example_collection\"):\n",
    "            print(\"Connection to Milvus successful, example collection exists.\")\n",
    "        else:\n",
    "            print(\"Connection to Milvus successful, example collection does not exist.\")\n",
    "    except Exception as e:\n",
    "        print(\"Failed to connect to Milvus:\", e)\n",
    "\n",
    "def create_sample_collection():\n",
    "    from pymilvus import Collection, FieldSchema, CollectionSchema, DataType\n",
    "\n",
    "    # Define the schema\n",
    "    fields = [\n",
    "        FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=True),\n",
    "        FieldSchema(name=\"vector\", dtype=DataType.FLOAT_VECTOR, dim=128),\n",
    "    ]\n",
    "    schema = CollectionSchema(fields, \"Sample schema for testing\")\n",
    "\n",
    "    # Create a collection named \"example_collection\"\n",
    "    collection = Collection(\"example_collection\", schema)\n",
    "    print(\"Collection created:\", collection.name)\n",
    "\n",
    "    return collection\n",
    "\n",
    "def insert_sample_data(collection):\n",
    "    import numpy as np\n",
    "\n",
    "    # Generate sample data\n",
    "    vectors = np.random.random([10, 128]).astype(\"float32\")  # 10 vectors of dimension 128\n",
    "    data = [vectors]\n",
    "\n",
    "    # Insert data\n",
    "    collection.insert(data)\n",
    "    print(\"Sample data inserted into collection:\", collection.name)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Testing connection to Milvus:\")\n",
    "    test_milvus_connection()\n",
    "\n",
    "    # Optional: Create and insert data if connected successfully\n",
    "    collection_name = \"example_collection\"\n",
    "    if not utility.has_collection(collection_name):\n",
    "        print(\"Creating collection and inserting sample data.\")\n",
    "        collection = create_sample_collection()\n",
    "        insert_sample_data(collection)\n",
    "    else:\n",
    "        print(\"Collection already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Milvus Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index created on 'embedding' field.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import markdown\n",
    "from pathlib import Path\n",
    "# Vectorization model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Connect to Milvus\n",
    "connections.connect(\"default\", host=MILVUS_HOST, port=MILVUS_PORT)\n",
    "\n",
    "# Define Milvus schema\n",
    "collection_name = \"product_details\"\n",
    "fields = [\n",
    "    FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=True),\n",
    "    FieldSchema(name=\"text_chunk\", dtype=DataType.VARCHAR, max_length=1024),\n",
    "    FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=384),\n",
    "]\n",
    "schema = CollectionSchema(fields, \"Schema for Markdown file vectors\")\n",
    "\n",
    "# Create collection if it doesn't exist\n",
    "if not utility.has_collection(collection_name):\n",
    "    collection = Collection(name=collection_name, schema=schema)\n",
    "else:\n",
    "    collection = Collection(name=collection_name)\n",
    "\n",
    "# Ensure the index on the embedding field\n",
    "index_params = {\n",
    "    \"metric_type\": \"L2\",\n",
    "    \"index_type\": \"IVF_FLAT\",\n",
    "    \"params\": {\"nlist\": 128}\n",
    "}\n",
    "\n",
    "# Check if an index already exists; create if it doesn't\n",
    "if not collection.has_index():\n",
    "    collection.create_index(field_name=\"embedding\", index_params=index_params)\n",
    "    print(\"Index created on 'embedding' field.\")\n",
    "else:\n",
    "    print(\"Index already exists on 'embedding' field.\")\n",
    "    \n",
    "\n",
    "def read_md_files(md_dir):\n",
    "    \"\"\"Read and parse markdown files from a directory.\"\"\"\n",
    "    md_texts = []\n",
    "    for md_file in Path(md_dir).rglob(\"*.md\"):\n",
    "        with open(md_file, \"r\", encoding=\"utf-8\") as file:\n",
    "            text = file.read()\n",
    "            html = markdown.markdown(text)\n",
    "            md_texts.append(html)\n",
    "    return md_texts\n",
    "\n",
    "\n",
    "def chunk_text(text, chunk_size=1000, chunk_overlap=100):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    return text_splitter.split_text(text)\n",
    "\n",
    "def vectorize_and_insert(md_dir):\n",
    "    \"\"\"Chunk, vectorize, and insert Markdown text data into Milvus.\"\"\"\n",
    "    md_texts = read_md_files(md_dir)\n",
    "    \n",
    "    # Prepare data for insertion\n",
    "    all_text_chunks = []\n",
    "    all_vectors = []\n",
    "    \n",
    "    for md_text in md_texts:\n",
    "        chunks = chunk_text(md_text)\n",
    "        embeddings = model.encode(chunks, show_progress_bar=True)\n",
    "        \n",
    "        # Collect data for Milvus insertion\n",
    "        all_text_chunks.extend(chunks)\n",
    "        all_vectors.extend(embeddings)\n",
    "\n",
    "    # Insert into Milvus\n",
    "    collection.insert([all_text_chunks, all_vectors])\n",
    "    print(f\"Inserted {len(all_vectors)} vectors into Milvus.\")\n",
    "\n",
    "\n",
    "# Directory containing markdown files\n",
    "markdown_directory = \"../docs/product_details\"  # Update to your directory\n",
    "vectorize_and_insert(markdown_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Milvus Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import Collection\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Initialize the embedding model (same as used for data insertion)\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def query_milvus(collection_name, query_text, top_k=3):\n",
    "    \"\"\"\n",
    "    Query the Milvus index with a string and return the top K matches.\n",
    "\n",
    "    Parameters:\n",
    "    - collection_name (str): Name of the Milvus collection.\n",
    "    - query_text (str): The query string to search for.\n",
    "    - top_k (int): The number of top matches to return (default is 3).\n",
    "\n",
    "    Returns:\n",
    "    - List of dictionaries with fields: \"id\", \"text_chunk\", and \"score\".\n",
    "    \"\"\"\n",
    "    # Load the collection\n",
    "    collection = Collection(name=collection_name)\n",
    "\n",
    "    # Ensure the collection is loaded into memory\n",
    "    collection.load()\n",
    "\n",
    "    # Vectorize the query text\n",
    "    query_embedding = model.encode([query_text])[0]  # Single vector\n",
    "\n",
    "    # Perform search\n",
    "    search_params = {\"metric_type\": \"L2\", \"params\": {\"nprobe\": 10}}\n",
    "    results = collection.search(\n",
    "        data=[query_embedding],  # Query vector\n",
    "        anns_field=\"embedding\",\n",
    "        param=search_params,\n",
    "        limit=top_k,\n",
    "        output_fields=[\"text_chunk\"]  # Retrieve the text chunk field\n",
    "    )\n",
    "\n",
    "    # Process and return results\n",
    "    top_matches = []\n",
    "    for result in results[0]:  # results[0] because search returns a list of lists\n",
    "        match = {\n",
    "            \"id\": result.id,\n",
    "            \"text_chunk\": result.entity.get(\"text_chunk\"),\n",
    "            \"score\": result.distance  # Lower scores indicate closer matches for \"L2\"\n",
    "        }\n",
    "        top_matches.append(match)\n",
    "\n",
    "    return top_matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top matches: [{'id': 453547963383558184, 'text_chunk': '<h2><strong>1. CloudForge Migrate</strong></h2>\\n<h3><strong>Detailed Description</strong></h3>\\n<p><strong>CloudForge Migrate</strong> is an all-in-one cloud migration platform designed to simplify the complex process of moving applications, data, and infrastructure to the cloud. It provides a seamless transition from on-premises or legacy systems to modern cloud environments, supporting public, private, and hybrid cloud models across major providers like AWS, Microsoft Azure, and Google Cloud Platform.</p>\\n<p><strong>Key Components:</strong></p>\\n<ul>\\n<li><strong>Migration Assessment Module:</strong> Analyzes your existing IT landscape to create a detailed migration plan, identifying dependencies, potential risks, and optimization opportunities.</li>\\n<li><strong>Data Migration Engine:</strong> Handles the secure transfer of databases and files, ensuring data integrity and minimal downtime.</li>', 'score': 0.4729633331298828}, {'id': 453547963383558320, 'text_chunk': '<h2><strong>1. CloudForge Migrate</strong></h2>\\n<h3><strong>Detailed Description</strong></h3>\\n<p><strong>CloudForge Migrate</strong> is an all-in-one cloud migration platform designed to simplify the complex process of moving applications, data, and infrastructure to the cloud. It provides a seamless transition from on-premises or legacy systems to modern cloud environments, supporting public, private, and hybrid cloud models across major providers like AWS, Microsoft Azure, and Google Cloud Platform.</p>\\n<p><strong>Key Components:</strong></p>\\n<ul>\\n<li><strong>Migration Assessment Module:</strong> Analyzes your existing IT landscape to create a detailed migration plan, identifying dependencies, potential risks, and optimization opportunities.</li>\\n<li><strong>Data Migration Engine:</strong> Handles the secure transfer of databases and files, ensuring data integrity and minimal downtime.</li>', 'score': 0.4729633331298828}, {'id': 453547963383558115, 'text_chunk': '</ul>\\n<h3><strong>Risk Analysis</strong></h3>\\n<ul>\\n<li><strong>Market Competition</strong>: Stay ahead through continuous innovation and customer engagement.</li>\\n<li><strong>Technological Changes</strong>: Invest in R&amp;D to adapt to emerging technologies and industry trends.</li>\\n<li><strong>Security Concerns</strong>: Implement robust security measures to protect client data and maintain trust.</li>\\n</ul>\\n<hr />\\n<h2><strong>Major Products</strong></h2>\\n<h3><strong>1. CloudForge Migrate</strong></h3>\\n<p><strong>Simplify Your Journey to the Cloud</strong></p>\\n<p><strong>Description</strong>: CloudForge Migrate is a comprehensive cloud migration tool that automates the process of moving applications, data, and infrastructure to the cloud. It supports multi-cloud environments, including AWS, Azure, and Google Cloud.</p>\\n<p><strong>Key Features</strong>:</p>\\n<ul>\\n<li><strong>Automated Assessment</strong>: Analyzes existing infrastructure to plan optimal migration paths.</li>', 'score': 0.5018839836120605}]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "collection_name = \"product_details\"\n",
    "query_text = \"What is CloudForge Migrate?\"\n",
    "top_matches = query_milvus(collection_name, query_text)\n",
    "print(\"Top matches:\", top_matches)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kfp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
